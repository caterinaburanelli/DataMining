{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "tired-columbia",
   "metadata": {
    "gather": {
     "logged": 1621276318267
    }
   },
   "outputs": [],
   "source": [
    "#import xgboost as xgb\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "#from sklearn.model_selection import GroupShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passing-belfast",
   "metadata": {},
   "source": [
    "### Feature eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "molecular-metro",
   "metadata": {
    "gather": {
     "logged": 1621276321410
    }
   },
   "outputs": [],
   "source": [
    "### reading and sampling the data\n",
    "\n",
    "def read_file(path):\n",
    "    \"\"\"\n",
    "    reads the file in pandas df and converts the date_time column to datetime type\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "    df['date_time'] = pd.to_datetime(df['date_time'])\n",
    "    return df\n",
    "\n",
    "def sample_on_srch_id(df, frac = 0.1):\n",
    "    \"\"\"\n",
    "    samples the dataframe based on the fraction of srach_id\n",
    "    \"\"\"\n",
    "    # get unique srch_ids\n",
    "    srch_ids = np.unique(df.srch_id)\n",
    "    # calculate how many ids to return\n",
    "    chosen_k = int(len(srch_ids) * frac)\n",
    "    # sample ids\n",
    "    chosen_ids = random.sample(list(srch_ids), k = chosen_k)\n",
    "    # filter the df to only have sampled ids\n",
    "    return df[df['srch_id'].isin(chosen_ids)]\n",
    "\n",
    "### Feature Engineering --------------------------\n",
    "\n",
    "## missing data ----------------------------------\n",
    "\n",
    "def remove_missing_values(df):\n",
    "    \"\"\"\n",
    "    removes columns with more than 50 percent missing data\n",
    "    \"\"\"\n",
    "    missing_values = df.isna().mean().round(4) * 100\n",
    "    missing_values = pd.DataFrame(missing_values).reset_index()\n",
    "    missing_values.columns = [\"column\", \"missing\"]\n",
    "    # filter where there are missing values\n",
    "    missing_values.query(\"missing > 50\", inplace=True)  # remove columns with more than 50 % of missing values\n",
    "    missing_values.sort_values(\"missing\", inplace=True)\n",
    "    #print(missing_values)\n",
    "    df.drop(missing_values.column, axis=1, inplace=True)\n",
    "\n",
    "def replace_missing_values(df):\n",
    "    \"\"\"\n",
    "    imputes missing values with -1\n",
    "    \"\"\"\n",
    "    df.fillna(value=-1, inplace=True) \n",
    "\n",
    "## new features ----------------------------------\n",
    "\n",
    "def extract_time(df):\n",
    "    \"\"\" \n",
    "    month, week, day of the week and hour of search\n",
    "    \"\"\"\n",
    "    df_datetime = pd.DatetimeIndex(df.date_time)\n",
    "    df[\"month\"] = df_datetime.month\n",
    "    df[\"week\"] = df_datetime.week\n",
    "    df[\"day\"] = df_datetime.dayofweek + 1\n",
    "    df[\"hour\"] = df_datetime.hour\n",
    "    del df['date_time']\n",
    "\n",
    "def new_historical_price(df):\n",
    "    \"\"\"\n",
    "    'unlogs' prop_log_historical_price column\n",
    "    \"\"\"\n",
    "    df[\"prop_historical_price\"] = (np.e ** df.prop_log_historical_price).replace(1.0, 0)\n",
    "    df.drop(\"prop_log_historical_price\", axis=1, inplace=True)\n",
    "\n",
    "def add_price_position(df, rank_type = \"dense\"):\n",
    "    \"\"\"\n",
    "    adds hotel price position (\"price_position\") inside \"srch_id\" column\n",
    "    \"\"\"\n",
    "    ranks = df.groupby('srch_id')['price_usd'].rank(ascending=True, method = rank_type)\n",
    "    df[\"price_position\"] = ranks\n",
    "\n",
    "\n",
    "def average_numerical_features(df, group_by = [\"prop_id\"], columns = [\"prop_starrating\", \"prop_review_score\", \"prop_location_score1\", \"prop_location_score2\"]):\n",
    "    \"\"\"\n",
    "    adds mean, median and standard deviation per prop_id (default) \n",
    "    for columns that are related to property (default)\n",
    "    \"\"\"\n",
    "    # caulcate means and rename columns\n",
    "    means = df.groupby(group_by)[columns].mean().reset_index()\n",
    "    means.columns = [means.columns[0]] + [x + \"_mean\" for x in means.columns[1:]]\n",
    "    # caulcate median and rename columns\n",
    "    medians = df.groupby(group_by)[columns].median().reset_index()\n",
    "    medians.columns = [medians.columns[0]] + [x + \"_median\" for x in medians.columns[1:]]\n",
    "    # caulcate means and rename columns\n",
    "    stds = df.groupby(group_by)[columns].std().reset_index()\n",
    "    stds.columns = [stds.columns[0]] + [x + \"_std\" for x in stds.columns[1:]]\n",
    "    ## attach aggregated data to the df\n",
    "    df = pd.merge(df, means, on=group_by)\n",
    "    df = pd.merge(df, medians, on=group_by)\n",
    "    df = pd.merge(df, stds, on=group_by)\n",
    "    return df\n",
    "\n",
    "def add_historical_booking_click(df):\n",
    "    \"\"\"\n",
    "    creates a column with the percentage of the prop_id booked/clicked rate overall\n",
    "    \"\"\"\n",
    "    # there are more prop_id in the test data than in train. \n",
    "    # Maybe we could still use this but would need to impute\n",
    "    # with the most common value (or something else)\n",
    "    \n",
    "    historical = df.groupby(\"prop_id\")[[\"click_bool\", \"booking_bool\"]].mean().reset_index()\n",
    "    historical.columns = [historical.columns[0]] + [x + \"_rate\" for x in historical.columns[1:]]\n",
    "    df = pd.merge(df, historical, on=\"prop_id\")\n",
    "    df.sort_values(\"srch_id\", inplace = True)\n",
    "    return df\n",
    "\n",
    "def join_historical_data(df, path = \"hist_click_book.csv\"):\n",
    "    \"\"\"\n",
    "    joins historical data according to prop_id. \n",
    "    path - location of historical data csv file\n",
    "    \n",
    "    \"\"\"\n",
    "    to_join = pd.read_csv(path)\n",
    "    joined = pd.merge(df, to_join, on=\"prop_id\")\n",
    "    return joined.sort_values(\"srch_id\")\n",
    "\n",
    "def create_comp_rate_mode(df, fillna_ = -100):\n",
    "    \"\"\"\n",
    "    creates a column with the mode of comp_rate columns and fills the rest with -100 (default)\n",
    "    \"\"\"\n",
    "    #subset comp_rate\n",
    "    comp_rate_cols = [col for col in df.columns if col.endswith(\"_rate\")]\n",
    "    df[\"comp_rate_mode\"] = df[comp_rate_cols].mode(axis = 1, dropna = True)[0]\n",
    "    df[\"comp_rate_mode\"].fillna(fillna_ , inplace = True)\n",
    "\n",
    "def create_comp_inv_mode(df, fillna_ = -100):\n",
    "    \"\"\"\n",
    "    creates a column with the mode of comp_inv columns and fills the rest with -100 (default)\n",
    "    \"\"\"\n",
    "    comp_inv = [col for col in df.columns if col.endswith(\"_inv\")]\n",
    "    df[\"comp_inv_mode\"] = df[comp_inv].mode(axis = 1, dropna = True)[0]\n",
    "    df[\"comp_inv_mode\"].fillna(fillna_ , inplace = True)\n",
    "\n",
    "def normalize_features(df_mod, normalizing_var, column):\n",
    "    # df_mod = dataframe\n",
    "    # normalizing_var = variable that will be used for normalizing\n",
    "    # column = variable that will be normalized\n",
    "\n",
    "    methods = [\"mean\", \"std\"]\n",
    "\n",
    "    df = df_mod.groupby(normalizing_var).agg({column: methods})\n",
    "\n",
    "    df.columns = df.columns.droplevel()\n",
    "    col = {}\n",
    "    for method in methods:\n",
    "        col[method] = column + \"_\" + method\n",
    "\n",
    "    df.rename(columns=col, inplace=True)\n",
    "    df_merge = df_mod.merge(df.reset_index(), on=normalizing_var)\n",
    "    df_merge[column + \"_norm_by_\" + normalizing_var] = (\n",
    "        df_merge[column] - df_merge[column + \"_mean\"]\n",
    "    ) / df_merge[column + \"_std\"]\n",
    "    df_merge = df_merge.drop(labels=[col[\"mean\"], col[\"std\"]], axis=1)\n",
    "\n",
    "    return df_merge   \n",
    "\n",
    "def add_normalisation(df, target_list = [\"prop_starrating\", \"prop_review_score\", \"prop_location_score1\", \"prop_location_score2\"]):\n",
    "    for column in target_list:\n",
    "        df = normalize_features(df, normalizing_var=\"srch_id\", column=column)\n",
    "    return df \n",
    "    \n",
    "## other ----------------------------------\n",
    "\n",
    "def remove_cols(df, cols = [\"position\", \"prop_id\"]):\n",
    "    df.drop(cols, axis=1, inplace=True)\n",
    "\n",
    "def remove_positions(df, positions = [5, 11, 17, 23]):\n",
    "    \"\"\"\n",
    "    removes hotels with specified positions \n",
    "    (based on the fact that hotels in those positions were not as booked)\n",
    "    \"\"\"\n",
    "    df = df[df[\"position\"].isin(positions) == False]\n",
    "\n",
    "def add_score(df):\n",
    "    \"\"\"\n",
    "    adds 'score' column to the df: 5 for booked, 1 for clicked\n",
    "    \"\"\"\n",
    "    score = []\n",
    "    for book, click in zip(df.booking_bool, df.click_bool):\n",
    "        if book == 1:\n",
    "            score.append(5)\n",
    "            continue\n",
    "        if click == 1:\n",
    "            score.append(1)\n",
    "            continue\n",
    "        else:\n",
    "            score.append(0)\n",
    "    df[\"score\"] = score\n",
    "    del df['booking_bool']\n",
    "    del df['click_bool']\n",
    "\n",
    "def onehot(df, cols):\n",
    "    \"\"\" \n",
    "    returns a df with one-hot encoded columns (cols)\n",
    "    \"\"\"\n",
    "    \n",
    "    return pd.get_dummies(df, columns=cols)\n",
    "\n",
    "\n",
    "### Feature engineering function -----------\n",
    "\n",
    "def feature_engineering_train(df):\n",
    "    \n",
    "    extract_time(df)\n",
    "    create_comp_rate_mode(df)\n",
    "    create_comp_inv_mode(df)\n",
    "    remove_missing_values(df)\n",
    "    replace_missing_values(df)\n",
    "    new_historical_price(df)\n",
    "    add_price_position(df)\n",
    "    #df = average_numerical_features(df)\n",
    "    #df = add_historical_booking_click(df)\n",
    "    df = add_normalisation(df)\n",
    "    add_score(df)\n",
    "    # remove_cols(df)\n",
    "    return df\n",
    "\n",
    "def feature_engineering_train_2(df):\n",
    "    \n",
    "    extract_time(df)\n",
    "    remove_missing_values(df)\n",
    "    replace_missing_values(df)\n",
    "    new_historical_price(df)\n",
    "    add_price_position(df)\n",
    "    #df = average_numerical_features(df)\n",
    "    #df = add_historical_booking_click(df)\n",
    "    df = add_normalisation(df)\n",
    "    add_score(df)\n",
    "    #remove_cols(df)\n",
    "    return df\n",
    "\n",
    "def feature_engineering_test(df):\n",
    "    \n",
    "    extract_time(df)\n",
    "    create_comp_rate_mode(df)\n",
    "    create_comp_inv_mode(df)\n",
    "    remove_missing_values(df)\n",
    "    replace_missing_values(df)\n",
    "    new_historical_price(df)\n",
    "    add_price_position(df)\n",
    "    #df = average_numerical_features(df)\n",
    "    df = add_normalisation(df)\n",
    "    return df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "accompanied-temperature",
   "metadata": {
    "gather": {
     "logged": 1621276327994
    }
   },
   "outputs": [],
   "source": [
    "def NDCG(predictions, df, path_idcg = \"idcg.csv\"):\n",
    "    \"\"\"\n",
    "    takes predicted positions and calulates average ndcg.\n",
    "    predictions - dataframe must have \"srch_id\" and \"prop_id\" ordered by relevance (inside \"srch_id\") (basically Lotte's model \"out\" dataframe)\n",
    "    df - training dataset (must contain \"srch_id\", \"prop_id\", \"score\")\n",
    "    path_idcg - path to idcg scores per \"srch_id\"\n",
    "    \"\"\"\n",
    "    # reset index \n",
    "    predictions.reset_index(drop = True, inplace = True)\n",
    "    # add position + 1\n",
    "    predictions[\"position\"] = predictions.groupby(by = ['srch_id']).cumcount()+1\n",
    "    # filter to only have positions up to 5\n",
    "    predictions = predictions[predictions.position < 6]\n",
    "    # attach scores to predictions\n",
    "    predictions = pd.merge(predictions, df[[\"srch_id\", \"prop_id\", \"score\"]], on = [\"srch_id\", \"prop_id\"])\n",
    "    predictions[\"numerator\"] = predictions[\"score\"]\n",
    "    predictions[\"denominator\"] = np.log2(predictions[\"position\"])\n",
    "    predictions.loc[predictions.position == 1, \"denominator\"] = 1\n",
    "    predictions[\"intermediate_dcg\"] = predictions[\"numerator\"]/predictions[\"denominator\"]\n",
    "    dcg = predictions.groupby(\"srch_id\")[\"intermediate_dcg\"].sum().reset_index()\n",
    "    dcg.columns = [\"scrh_id\", \"DCG\"]\n",
    "    # read idcg\n",
    "    idcg = pd.read_csv(path_idcg)\n",
    "    # attach idcg to dcg\n",
    "    joined = pd.merge(dcg, idcg, on = \"scrh_id\")\n",
    "    # calculate NDCG\n",
    "    joined[\"NDCG\"] = joined[\"DCG\"]/joined[\"iDCG\"]\n",
    "    # calculate mean NDCG\n",
    "    return joined[\"NDCG\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "formal-hepatitis",
   "metadata": {
    "gather": {
     "logged": 1621276331319
    }
   },
   "outputs": [],
   "source": [
    "def predict(model, df):\n",
    "    return model.predict(df.loc[:, ~df.columns.isin(['srch_id'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loose-logging",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promising-spencer",
   "metadata": {
    "gather": {
     "logged": 1621276333612
    }
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import DMatrix\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from sklearn.model_selection import GroupShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6351ce73-d48e-41ce-be55-2d9532079a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entire-biotechnology",
   "metadata": {
    "gather": {
     "logged": 1621272470795
    }
   },
   "outputs": [],
   "source": [
    "df_test = read_file(\"/Users/IggyMac/OneDrive - UvA/2020-2021/Data mining/Assignment2/data/test_set_VU_DM.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "coupled-german",
   "metadata": {
    "gather": {
     "logged": 1621276371699
    }
   },
   "outputs": [],
   "source": [
    "df_train = read_file(\"/Users/IggyMac/OneDrive - UvA/2020-2021/Data mining/Assignment2/data/training_set_VU_DM.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fde201-8820-40d0-bc10-93bcb280c150",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('/Users/IggyMac/OneDrive - UvA/2020-2021/Data mining/Github/assignment2/Model/engineered_training_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9800d5aa-985c-4c33-bca6-8b379fdfbb80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['srch_id', 'date_time', 'site_id', 'visitor_location_country_id',\n",
       "       'visitor_hist_starrating', 'visitor_hist_adr_usd', 'prop_country_id',\n",
       "       'prop_id', 'prop_starrating', 'prop_review_score', 'prop_brand_bool',\n",
       "       'prop_location_score1', 'prop_location_score2',\n",
       "       'prop_log_historical_price', 'position', 'price_usd', 'promotion_flag',\n",
       "       'srch_destination_id', 'srch_length_of_stay', 'srch_booking_window',\n",
       "       'srch_adults_count', 'srch_children_count', 'srch_room_count',\n",
       "       'srch_saturday_night_bool', 'srch_query_affinity_score',\n",
       "       'orig_destination_distance', 'random_bool', 'comp1_rate', 'comp1_inv',\n",
       "       'comp1_rate_percent_diff', 'comp2_rate', 'comp2_inv',\n",
       "       'comp2_rate_percent_diff', 'comp3_rate', 'comp3_inv',\n",
       "       'comp3_rate_percent_diff', 'comp4_rate', 'comp4_inv',\n",
       "       'comp4_rate_percent_diff', 'comp5_rate', 'comp5_inv',\n",
       "       'comp5_rate_percent_diff', 'comp6_rate', 'comp6_inv',\n",
       "       'comp6_rate_percent_diff', 'comp7_rate', 'comp7_inv',\n",
       "       'comp7_rate_percent_diff', 'comp8_rate', 'comp8_inv',\n",
       "       'comp8_rate_percent_diff', 'click_bool', 'gross_bookings_usd',\n",
       "       'booking_bool'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hawaiian-trust",
   "metadata": {
    "gather": {
     "logged": 1621272526969
    }
   },
   "outputs": [],
   "source": [
    "d1_test = df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classical-registration",
   "metadata": {
    "gather": {
     "logged": 1621272647801
    }
   },
   "outputs": [],
   "source": [
    "d1_train = df_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diagnostic-deposit",
   "metadata": {
    "gather": {
     "logged": 1621166950607
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-755bbca02b0d>:55: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)\n",
      "  df[\"week\"] = df_datetime.week\n"
     ]
    }
   ],
   "source": [
    "df = feature_engineering_train(df_train)\n",
    "#df_2 = feature_engineering_train(d1_train)\n",
    "#testset = feature_engineering_test(d1_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7b24e2-bc03-4fa9-b9e8-daa658c4c797",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"engineered_training_data.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db55d03-eea9-446f-9b1f-b51ccd1c4fb3",
   "metadata": {
    "gather": {
     "logged": 1621166951753
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f5a4c0-1fe9-46c6-bd54-a68b3bc1cab5",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "df_2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "median-stack",
   "metadata": {},
   "outputs": [],
   "source": [
    "#properties = testset['prop_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "front-hollow",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del df['prop_id']\n",
    "#del df['position']\n",
    "#del testset['prop_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medium-burns",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "significant-tampa",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electric-journalism",
   "metadata": {},
   "source": [
    "### Parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eleven-decision",
   "metadata": {
    "gather": {
     "logged": 1621166964672
    }
   },
   "outputs": [],
   "source": [
    "def tuning_model(df, learning_rate, max_depth, n_estimators, objective):\n",
    "    \n",
    "    # data\n",
    "    #del df['position']\n",
    "    gss = GroupShuffleSplit(test_size=.3, n_splits=1, random_state = 7).split(df, groups=df['srch_id'])\n",
    "\n",
    "    X_train_inds, X_test_inds = next(gss)\n",
    "    train_data= df.iloc[X_train_inds]\n",
    "    test_data= df.iloc[X_test_inds]\n",
    "    properties = test_data['prop_id']\n",
    "    del train_data['prop_id']\n",
    "    del test_data['prop_id']\n",
    "    #del df['prop_id']\n",
    "\n",
    "\n",
    "    X_train = train_data.loc[:, ~train_data.columns.isin(['srch_id','score'])]\n",
    "    #X_train = train_data.loc[:, ~train_data.columns.isin(['srch_id'])]\n",
    "\n",
    "    y_train = train_data.loc[:, train_data.columns.isin(['score'])]\n",
    "\n",
    "    groups = train_data.groupby('srch_id').size().to_frame('size')['size'].to_numpy()\n",
    "\n",
    "\n",
    "    #We need to keep the id for later predictions\n",
    "    X_test = test_data.loc[:, ~test_data.columns.isin(['score'])]\n",
    "    y_test = test_data.loc[:, test_data.columns.isin(['score'])]\n",
    "\n",
    "\n",
    "    model = xgb.XGBRanker(  \n",
    "    tree_method='hist',\n",
    "    booster='gbtree',\n",
    "    objective=objective,\n",
    "    random_state=42,    \n",
    "    learning_rate=learning_rate,\n",
    "    colsample_bytree=0.9,  \n",
    "    max_depth=max_depth, \n",
    "    n_estimators=n_estimators, \n",
    "    subsample=0.75 \n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train, group=groups, verbose=True)\n",
    "    \n",
    "\n",
    "    predictions = (X_test.groupby('srch_id').apply(lambda x: predict(model, x)))\n",
    "    output = pd.DataFrame()\n",
    "    output[\"srch_id\"] = test_data[\"srch_id\"]\n",
    "    output[\"prop_id\"] = properties\n",
    "\n",
    "    # Add scores\n",
    "    pred_scores_list = []\n",
    "\n",
    "    for i in predictions:\n",
    "        for j in i:\n",
    "            pred_scores_list.append(j)      \n",
    "\n",
    "    output[\"pred_scores\"] = pred_scores_list\n",
    "    \n",
    "    out = output.groupby('srch_id').apply(pd.DataFrame.sort_values, 'pred_scores', ascending=False)\n",
    "    del out[\"pred_scores\"]\n",
    "    #out.to_csv('../data/submission_cate.csv', index=False)\n",
    "    \n",
    "    return NDCG(out, df, path_idcg = \"idcg.csv\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removable-medication",
   "metadata": {
    "gather": {
     "logged": 1621188114961
    }
   },
   "outputs": [],
   "source": [
    "df_reduct = sample_on_srch_id(df, frac = 0.1)\n",
    "\n",
    "learning_rate=0.025\n",
    "colsample_bytree=0.9\n",
    "max_depth=6\n",
    "n_estimators=800\n",
    "subsample=0.75\n",
    "objective = \"rank:pairwise\"\n",
    "tuning_model(df = df, learning_rate = learning_rate, colsample_bytree = 0.9, max_depth = max_depth, n_estimators = n_estimators, objective = objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cutting-emphasis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attempt 1\n",
    "\n",
    "learning_rate_ = [0.4, 0.3, 0.1, 0.05, 0.025, 0.01]\n",
    "max_depth_=[6, 8, 10, 12, 15, 20, 30] # Maximum depth of a tree\n",
    "n_estimators_ =[110, 150, 200, 300, 500]\n",
    "objective_ = [\"rank:pairwise\", \"rank:ndcg\", \"rank:map\"]\n",
    "\n",
    "l_r = []\n",
    "m_d = []\n",
    "n_e = []\n",
    "obj = []\n",
    "ndcg = []\n",
    "i = 1\n",
    "\n",
    "df_reduct = sample_on_srch_id(df, frac = 0.1)\n",
    "\n",
    "\n",
    "for learning_rate in learning_rate_:\n",
    "    for max_depth in max_depth_:\n",
    "        for n_estimators in n_estimators_:\n",
    "            for objective in objective_:\n",
    "                ndcg_ = tuning_model(df = df_reduct, learning_rate = learning_rate, colsample_bytree = 0.9, max_depth = max_depth, n_estimators = n_estimators, objective = objective)\n",
    "                ndcg.append(ndcg_)\n",
    "                l_r.append(learning_rate)\n",
    "                m_d.append(max_depth)\n",
    "                n_e.append(n_estimators)\n",
    "                obj.append(objective)\n",
    "                #print(learning_rate, max_depth, n_estimators, objective, ndcg_, i)\n",
    "                data_frame = pd.DataFrame({\"learning_rate\": [learning_rate],\n",
    "                                            \"max_depth\": [max_depth],\n",
    "                                            \"n_estimators\": [n_estimators],\n",
    "                                            \"objective\": [objective],\n",
    "                                            \"NDCG\": [ndcg_]})\n",
    "                data_frame.to_csv(\"tuning_outputs/\"+ str(i) + \".csv\")\n",
    "                i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a3b5c3-7f5e-4239-a9a9-0b68ab4d7d32",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# attempt 2\n",
    "\n",
    "learning_rate_ = [0.1, 0.05, 0.025, 0.01, 0.075]\n",
    "max_depth_=[6, 8, 10, 12, 15, 20] # Maximum depth of a tree\n",
    "n_estimators_ =[750, 800, 1000]\n",
    "objective = \"rank:pairwise\"\n",
    "\n",
    "l_r = []\n",
    "m_d = []\n",
    "n_e = []\n",
    "obj = []\n",
    "ndcg = []\n",
    "i = 1\n",
    "\n",
    "df_reduct = sample_on_srch_id(df, frac = 0.1)\n",
    "\n",
    "\n",
    "for learning_rate in learning_rate_:\n",
    "    for max_depth in max_depth_:\n",
    "        for n_estimators in n_estimators_:\n",
    "                ndcg_ = tuning_model(df = df_reduct, learning_rate = learning_rate, colsample_bytree = 0.9, max_depth = max_depth, n_estimators = n_estimators, objective = objective)\n",
    "                ndcg.append(ndcg_)\n",
    "                l_r.append(learning_rate)\n",
    "                m_d.append(max_depth)\n",
    "                n_e.append(n_estimators)\n",
    "                obj.append(objective)\n",
    "                #print(learning_rate, max_depth, n_estimators, objective, ndcg_, i)\n",
    "                data_frame = pd.DataFrame({\"learning_rate\": [learning_rate],\n",
    "                                            \"max_depth\": [max_depth],\n",
    "                                            \"n_estimators\": [n_estimators],\n",
    "                                            \"objective\": [objective],\n",
    "                                            \"NDCG\": [ndcg_]})\n",
    "                data_frame.to_csv(\"tuning_outputs_02/\"+ str(i) + \".csv\")\n",
    "                i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greatest-medicine",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning = pd.DataFrame(list(zip(e, d, est, ndcg)),\n",
    "               columns =['eta', 'max_depth', 'n_estimators', 'NDCG'])\n",
    "print(tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleasant-knife",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "synthetic-lawyer",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weekly-right",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modeling(df, testset, learning_rate, colsample_bytree, eta, max_depth, n_estimators):\n",
    "    \n",
    "    # data\n",
    "    properties = testset['prop_id']\n",
    "    del testset['prop_id']\n",
    "    \n",
    "\n",
    "    X_train = df.loc[:, ~df.columns.isin(['srch_id','score'])]\n",
    "    y_train = df.loc[:, df.columns.isin(['score'])]\n",
    "    X_test = testset\n",
    "    groups = df.groupby('srch_id').size().to_frame('size')['size'].to_numpy()\n",
    "\n",
    "\n",
    "    model = xgb.XGBRanker(  \n",
    "    tree_method='hist',\n",
    "    booster='gbtree',\n",
    "    objective='rank:pairwise',\n",
    "    #eval_metric = [\"ndcg\", \"map\"],\n",
    "    random_state=42,    \n",
    "    learning_rate=learning_rate,\n",
    "    colsample_bytree=colsample_bytree, \n",
    "    eta=eta, \n",
    "    max_depth=max_depth, \n",
    "    n_estimators=n_estimators, \n",
    "    subsample=subsample \n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train, group=groups, verbose=True)\n",
    "    \n",
    "\n",
    "    predictions = (testset.groupby('srch_id').apply(lambda x: predict(model, x)))    output = pd.DataFrame()\n",
    "    output[\"srch_id\"] = test_data[\"srch_id\"]\n",
    "    output[\"prop_id\"] = properties\n",
    "\n",
    "    # Add scores\n",
    "    pred_scores_list = []\n",
    "\n",
    "    for i in predictions:\n",
    "        for j in i:\n",
    "            pred_scores_list.append(j)      \n",
    "\n",
    "    output[\"pred_scores\"] = pred_scores_list\n",
    "    \n",
    "    out = output.groupby('srch_id').apply(pd.DataFrame.sort_values, 'pred_scores', ascending=False)\n",
    "    del out[\"pred_scores\"]\n",
    "    out.to_csv('../data/submission_cate.csv', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collectible-titanium",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.1\n",
    "colsample_bytree=0.9\n",
    "eta=0.05\n",
    "max_depth=6\n",
    "n_estimators=150\n",
    "subsample=0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-ribbon",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling(df, testset, learning_rate, colsample_bytree, eta, max_depth, n_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drawn-forwarding",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.loc[:, ~df.columns.isin(['srch_id','score'])]\n",
    "y_train = df.loc[:, df.columns.isin(['score'])]\n",
    "\n",
    "X_test = testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liberal-communications",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = df.groupby('srch_id').size().to_frame('size')['size'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacterial-music",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBRanker(  \n",
    "    tree_method='hist',\n",
    "    booster='gbtree',\n",
    "    objective='rank:pairwise',\n",
    "    eval_metric = [\"ndcg\", \"map\"],\n",
    "    random_state=42, \n",
    "    learning_rate=0.1,\n",
    "    colsample_bytree=0.9, \n",
    "    eta=0.05, \n",
    "    max_depth=6, \n",
    "    n_estimators=110, \n",
    "    subsample=0.75 \n",
    "    )\n",
    "\n",
    "model.fit(X_train, y_train, group=groups, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "practical-pointer",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = (testset.groupby('srch_id')\n",
    "               .apply(lambda x: predict(model, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compatible-samba",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ancient-placement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This could be done more efficiently\n",
    "\n",
    "# Prepare output file\n",
    "output = pd.DataFrame()\n",
    "output[\"srch_id\"] = testset[\"srch_id\"]\n",
    "output[\"prop_id\"] = properties\n",
    "\n",
    "# Add scores\n",
    "pred_scores_list = []\n",
    "\n",
    "for i in predictions:\n",
    "    for j in i:\n",
    "        pred_scores_list.append(j)      \n",
    "\n",
    "output[\"pred_scores\"] = pred_scores_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-offering",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = output.groupby('srch_id').apply(pd.DataFrame.sort_values, 'pred_scores', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animal-shame",
   "metadata": {},
   "outputs": [],
   "source": [
    "del out[\"pred_scores\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signal-participation",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "combined-welsh",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.to_csv('../data/submission_cate.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dental-change",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_importance(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "golden-endorsement",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
