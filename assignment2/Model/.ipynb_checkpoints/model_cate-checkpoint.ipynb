{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "varying-memorabilia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "alpine-chamber",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srch_id</th>\n",
       "      <th>site_id</th>\n",
       "      <th>visitor_location_country_id</th>\n",
       "      <th>visitor_hist_starrating</th>\n",
       "      <th>visitor_hist_adr_usd</th>\n",
       "      <th>prop_country_id</th>\n",
       "      <th>prop_id</th>\n",
       "      <th>prop_starrating</th>\n",
       "      <th>prop_review_score</th>\n",
       "      <th>prop_brand_bool</th>\n",
       "      <th>...</th>\n",
       "      <th>comp6_rate_percent_diff</th>\n",
       "      <th>comp7_rate</th>\n",
       "      <th>comp7_inv</th>\n",
       "      <th>comp7_rate_percent_diff</th>\n",
       "      <th>comp8_rate</th>\n",
       "      <th>comp8_inv</th>\n",
       "      <th>comp8_rate_percent_diff</th>\n",
       "      <th>click_bool</th>\n",
       "      <th>gross_bookings_usd</th>\n",
       "      <th>booking_bool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.958347e+06</td>\n",
       "      <td>4.958347e+06</td>\n",
       "      <td>4.958347e+06</td>\n",
       "      <td>251866.000000</td>\n",
       "      <td>252988.000000</td>\n",
       "      <td>4.958347e+06</td>\n",
       "      <td>4.958347e+06</td>\n",
       "      <td>4.958347e+06</td>\n",
       "      <td>4.950983e+06</td>\n",
       "      <td>4.958347e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>96174.000000</td>\n",
       "      <td>315348.000000</td>\n",
       "      <td>356422.000000</td>\n",
       "      <td>138515.000000</td>\n",
       "      <td>1.916654e+06</td>\n",
       "      <td>1.987503e+06</td>\n",
       "      <td>614730.000000</td>\n",
       "      <td>4.958347e+06</td>\n",
       "      <td>138390.000000</td>\n",
       "      <td>4.958347e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.663666e+05</td>\n",
       "      <td>9.953133e+00</td>\n",
       "      <td>1.753405e+02</td>\n",
       "      <td>3.374334</td>\n",
       "      <td>176.022659</td>\n",
       "      <td>1.739739e+02</td>\n",
       "      <td>7.007918e+04</td>\n",
       "      <td>3.180525e+00</td>\n",
       "      <td>3.777777e+00</td>\n",
       "      <td>6.346994e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>17.250473</td>\n",
       "      <td>0.145969</td>\n",
       "      <td>0.083202</td>\n",
       "      <td>19.433267</td>\n",
       "      <td>-6.089936e-02</td>\n",
       "      <td>9.962752e-03</td>\n",
       "      <td>22.430384</td>\n",
       "      <td>4.474858e-02</td>\n",
       "      <td>386.283316</td>\n",
       "      <td>2.791051e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.611223e+04</td>\n",
       "      <td>7.646890e+00</td>\n",
       "      <td>6.591625e+01</td>\n",
       "      <td>0.692519</td>\n",
       "      <td>107.254493</td>\n",
       "      <td>6.834525e+01</td>\n",
       "      <td>4.060992e+04</td>\n",
       "      <td>1.051024e+00</td>\n",
       "      <td>1.050329e+00</td>\n",
       "      <td>4.815144e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>31.160313</td>\n",
       "      <td>0.578202</td>\n",
       "      <td>0.316722</td>\n",
       "      <td>54.370221</td>\n",
       "      <td>4.691723e-01</td>\n",
       "      <td>2.029142e-01</td>\n",
       "      <td>895.965854</td>\n",
       "      <td>2.067514e-01</td>\n",
       "      <td>821.190577</td>\n",
       "      <td>1.647165e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.410000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.293600e+04</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>2.920000</td>\n",
       "      <td>109.810000</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>3.501000e+04</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>3.500000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.665070e+05</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>2.190000e+02</td>\n",
       "      <td>3.450000</td>\n",
       "      <td>152.240000</td>\n",
       "      <td>2.190000e+02</td>\n",
       "      <td>6.963800e+04</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>218.400000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.497240e+05</td>\n",
       "      <td>1.400000e+01</td>\n",
       "      <td>2.190000e+02</td>\n",
       "      <td>3.930000</td>\n",
       "      <td>213.490000</td>\n",
       "      <td>2.190000e+02</td>\n",
       "      <td>1.051680e+05</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>4.500000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>429.790000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.327850e+05</td>\n",
       "      <td>3.400000e+01</td>\n",
       "      <td>2.310000e+02</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1958.700000</td>\n",
       "      <td>2.300000e+02</td>\n",
       "      <td>1.408210e+05</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1620.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9900.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>149400.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>159292.380000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            srch_id       site_id  visitor_location_country_id  \\\n",
       "count  4.958347e+06  4.958347e+06                 4.958347e+06   \n",
       "mean   1.663666e+05  9.953133e+00                 1.753405e+02   \n",
       "std    9.611223e+04  7.646890e+00                 6.591625e+01   \n",
       "min    1.000000e+00  1.000000e+00                 1.000000e+00   \n",
       "25%    8.293600e+04  5.000000e+00                 1.000000e+02   \n",
       "50%    1.665070e+05  5.000000e+00                 2.190000e+02   \n",
       "75%    2.497240e+05  1.400000e+01                 2.190000e+02   \n",
       "max    3.327850e+05  3.400000e+01                 2.310000e+02   \n",
       "\n",
       "       visitor_hist_starrating  visitor_hist_adr_usd  prop_country_id  \\\n",
       "count            251866.000000         252988.000000     4.958347e+06   \n",
       "mean                  3.374334            176.022659     1.739739e+02   \n",
       "std                   0.692519            107.254493     6.834525e+01   \n",
       "min                   1.410000              0.000000     1.000000e+00   \n",
       "25%                   2.920000            109.810000     1.000000e+02   \n",
       "50%                   3.450000            152.240000     2.190000e+02   \n",
       "75%                   3.930000            213.490000     2.190000e+02   \n",
       "max                   5.000000           1958.700000     2.300000e+02   \n",
       "\n",
       "            prop_id  prop_starrating  prop_review_score  prop_brand_bool  ...  \\\n",
       "count  4.958347e+06     4.958347e+06       4.950983e+06     4.958347e+06  ...   \n",
       "mean   7.007918e+04     3.180525e+00       3.777777e+00     6.346994e-01  ...   \n",
       "std    4.060992e+04     1.051024e+00       1.050329e+00     4.815144e-01  ...   \n",
       "min    1.000000e+00     0.000000e+00       0.000000e+00     0.000000e+00  ...   \n",
       "25%    3.501000e+04     3.000000e+00       3.500000e+00     0.000000e+00  ...   \n",
       "50%    6.963800e+04     3.000000e+00       4.000000e+00     1.000000e+00  ...   \n",
       "75%    1.051680e+05     4.000000e+00       4.500000e+00     1.000000e+00  ...   \n",
       "max    1.408210e+05     5.000000e+00       5.000000e+00     1.000000e+00  ...   \n",
       "\n",
       "       comp6_rate_percent_diff     comp7_rate      comp7_inv  \\\n",
       "count             96174.000000  315348.000000  356422.000000   \n",
       "mean                 17.250473       0.145969       0.083202   \n",
       "std                  31.160313       0.578202       0.316722   \n",
       "min                   2.000000      -1.000000      -1.000000   \n",
       "25%                   6.000000       0.000000       0.000000   \n",
       "50%                  11.000000       0.000000       0.000000   \n",
       "75%                  18.000000       1.000000       0.000000   \n",
       "max                1620.000000       1.000000       1.000000   \n",
       "\n",
       "       comp7_rate_percent_diff    comp8_rate     comp8_inv  \\\n",
       "count            138515.000000  1.916654e+06  1.987503e+06   \n",
       "mean                 19.433267 -6.089936e-02  9.962752e-03   \n",
       "std                  54.370221  4.691723e-01  2.029142e-01   \n",
       "min                   2.000000 -1.000000e+00 -1.000000e+00   \n",
       "25%                   7.000000  0.000000e+00  0.000000e+00   \n",
       "50%                  12.000000  0.000000e+00  0.000000e+00   \n",
       "75%                  20.000000  0.000000e+00  0.000000e+00   \n",
       "max                9900.000000  1.000000e+00  1.000000e+00   \n",
       "\n",
       "       comp8_rate_percent_diff    click_bool  gross_bookings_usd  booking_bool  \n",
       "count            614730.000000  4.958347e+06       138390.000000  4.958347e+06  \n",
       "mean                 22.430384  4.474858e-02          386.283316  2.791051e-02  \n",
       "std                 895.965854  2.067514e-01          821.190577  1.647165e-01  \n",
       "min                   2.000000  0.000000e+00            0.000000  0.000000e+00  \n",
       "25%                   7.000000  0.000000e+00          124.000000  0.000000e+00  \n",
       "50%                  11.000000  0.000000e+00          218.400000  0.000000e+00  \n",
       "75%                  17.000000  0.000000e+00          429.790000  0.000000e+00  \n",
       "max              149400.000000  1.000000e+00       159292.380000  1.000000e+00  \n",
       "\n",
       "[8 rows x 53 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/training_set_VU_DM.csv\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elder-conservation",
   "metadata": {},
   "source": [
    "### Feature eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "rolled-bonus",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(path):\n",
    "    \"\"\"\n",
    "    reads the file in pandas df and converts the date_time column to datetime type\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "    df['date_time'] = pd.to_datetime(df['date_time'])\n",
    "    return df\n",
    "\n",
    "def sample_on_srch_id(df, frac = 0.1):\n",
    "    \"\"\"\n",
    "    samples the dataframe based on the fraction of srach_id\n",
    "    \"\"\"\n",
    "    # get unique srch_ids\n",
    "    srch_ids = np.unique(df.srch_id)\n",
    "    # calculate how many ids to return\n",
    "    chosen_k = int(len(srch_ids) * frac)\n",
    "    # sample ids\n",
    "    chosen_ids = random.sample(list(srch_ids), k = chosen_k)\n",
    "    # filter the df to only have sampled ids\n",
    "    return df[df['srch_id'].isin(chosen_ids)]\n",
    "\n",
    "### Feature Engineering --------------------------\n",
    "\n",
    "## missing data ----------------------------------\n",
    "\n",
    "def remove_missing_values(df):\n",
    "    \"\"\"\n",
    "    removes columns with more than 50 percent missing data\n",
    "    \"\"\"\n",
    "    missing_values = df.isna().mean().round(4) * 100\n",
    "    missing_values = pd.DataFrame(missing_values).reset_index()\n",
    "    missing_values.columns = [\"column\", \"missing\"]\n",
    "    # filter where there are missing values\n",
    "    missing_values.query(\"missing > 50\", inplace=True)  # remove columns with more than 50 % of missing values\n",
    "    missing_values.sort_values(\"missing\", inplace=True)\n",
    "    #print(missing_values)\n",
    "    df.drop(missing_values.column, axis=1, inplace=True)\n",
    "\n",
    "def replace_missing_values(df):\n",
    "    \"\"\"\n",
    "    imputes missing values with -1\n",
    "    \"\"\"\n",
    "    df.fillna(value=-1, inplace=True) \n",
    "\n",
    "## new features ----------------------------------\n",
    "\n",
    "def extract_time(df):\n",
    "    \"\"\" \n",
    "    month, week, day of the week and hour of search\n",
    "    \"\"\"\n",
    "    df_datetime = pd.DatetimeIndex(df.date_time)\n",
    "    df[\"month\"] = df_datetime.month\n",
    "    df[\"week\"] = df_datetime.week\n",
    "    df[\"day\"] = df_datetime.dayofweek + 1\n",
    "    df[\"hour\"] = df_datetime.hour\n",
    "    df.drop(\"date_time\", inplace=True, axis=1)\n",
    "\n",
    "def new_historical_price(df):\n",
    "    \"\"\"\n",
    "    'unlogs' prop_log_historical_price column\n",
    "    \"\"\"\n",
    "    df[\"prop_historical_price\"] = (np.e ** df.prop_log_historical_price).replace(1.0, 0)\n",
    "    df.drop(\"prop_log_historical_price\", axis=1, inplace=True)\n",
    "\n",
    "def add_price_position(df, rank_type = \"dense\"):\n",
    "    \"\"\"\n",
    "    adds hotel price position (\"price_position\") inside \"srch_id\" column\n",
    "    \"\"\"\n",
    "    ranks = df.groupby('srch_id')['price_usd'].rank(ascending=True, method = rank_type)\n",
    "    df[\"price_position\"] = ranks\n",
    "\n",
    "\n",
    "def average_numerical_features(df, group_by = [\"prop_id\"], columns = [\"prop_starrating\", \"prop_review_score\", \"prop_location_score1\", \"prop_location_score2\"]):\n",
    "    \"\"\"\n",
    "    adds mean, median and standard deviation per prop_id (default) \n",
    "    for columns that are related to property (default)\n",
    "    \"\"\"\n",
    "    # caulcate means and rename columns\n",
    "    means = df.groupby(group_by)[columns].mean().reset_index()\n",
    "    means.columns = [means.columns[0]] + [x + \"_mean\" for x in means.columns[1:]]\n",
    "    # caulcate median and rename columns\n",
    "    medians = df.groupby(group_by)[columns].median().reset_index()\n",
    "    medians.columns = [medians.columns[0]] + [x + \"_median\" for x in medians.columns[1:]]\n",
    "    # caulcate means and rename columns\n",
    "    stds = df.groupby(group_by)[columns].std().reset_index()\n",
    "    stds.columns = [stds.columns[0]] + [x + \"_std\" for x in stds.columns[1:]]\n",
    "    ## attach aggregated data to the df\n",
    "    df = pd.merge(df, means, on=group_by)\n",
    "    df = pd.merge(df, medians, on=group_by)\n",
    "    df = pd.merge(df, stds, on=group_by)\n",
    "    return df\n",
    "\n",
    "def add_historical_booking_click(df):\n",
    "    \"\"\"\n",
    "    creates a column with the percentage of the prop_id booked/clicked rate overall\n",
    "    \"\"\"\n",
    "    # there are more prop_id in the test data than in train. \n",
    "    # Maybe we could still use this but would need to impute\n",
    "    # with the most common value (or something else)\n",
    "    \n",
    "    historical = df.groupby(\"prop_id\")[[\"click_bool\", \"booking_bool\"]].mean().reset_index()\n",
    "    historical.columns = [historical.columns[0]] + [x + \"_rate\" for x in historical.columns[1:]]\n",
    "    df = pd.merge(df, historical, on=\"prop_id\")\n",
    "    return df\n",
    "    \n",
    "    \n",
    "## other ----------------------------------\n",
    "\n",
    "def remove_positions(df, positions = [5, 11, 17, 23]):\n",
    "    \"\"\"\n",
    "    removes hotels with specified positions \n",
    "    (based on the fact that hotels in those positions were not as booked)\n",
    "    \"\"\"\n",
    "    df = df[df[\"position\"].isin(positions) == False]\n",
    "    \n",
    "### Feature engineering function -----------\n",
    "\n",
    "def feature_engineering(df):\n",
    "    extract_time(df)\n",
    "    remove_missing_values(df)\n",
    "    replace_missing_values(df)\n",
    "    new_historical_price(df)\n",
    "    add_price_position(df)\n",
    "    average_numerical_features(df)\n",
    "\n",
    "def add_score(df):\n",
    "    \"\"\"\n",
    "    adds 'score' column to the df: 5 for booked, 1 for clicked\n",
    "    \"\"\"\n",
    "    score = []\n",
    "    for book, click in zip(df.booking_bool, df.click_bool):\n",
    "        if book == 1:\n",
    "            score.append(5)\n",
    "            continue\n",
    "        if click == 1:\n",
    "            score.append(1)\n",
    "            continue\n",
    "        else:\n",
    "            score.append(0)\n",
    "    df[\"score\"] = score\n",
    "\n",
    "def create_df_queries_freq(df):\n",
    "    df_queries = pd.DataFrame()\n",
    "    df_queries = pd.crosstab(index=df['srch_id'], columns='count', colnames=['srch_id'])\n",
    "    df_queries.sort_values(\"srch_id\")\n",
    "    df_queries.to_csv(\"../df_queries.csv\")\n",
    "    return pd.read_csv(\"../df_queries.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cellular-dictionary",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "described-government",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import DMatrix\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from sklearn.model_selection import GroupShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "banned-bathroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_true = read_file(\"../data/training_set_VU_DM.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "transsexual-jewelry",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_true.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "labeled-moderator",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-96-b2db71d54d22>:53: FutureWarning: weekofyear and week have been deprecated, please use DatetimeIndex.isocalendar().week instead, which returns a Series.  To exactly reproduce the behavior of week and weekofyear and return an Index, you may call pd.Int64Index(idx.isocalendar().week)\n",
      "  df[\"week\"] = df_datetime.week\n"
     ]
    }
   ],
   "source": [
    "feature_engineering(df)\n",
    "add_score(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-annotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "russian-stereo",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srch_id</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   srch_id  count\n",
       "0        1     28\n",
       "1        4     32\n",
       "2        6      5\n",
       "3        8     21\n",
       "4       11     33"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_queries = create_df_queries_freq(df)\n",
    "df_queries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "neutral-storm",
   "metadata": {},
   "outputs": [],
   "source": [
    "gss = GroupShuffleSplit(test_size=.20, n_splits=1, random_state = 7).split(df, groups=df['srch_id'])\n",
    "\n",
    "X_train_inds, X_test_inds = next(gss)\n",
    "\n",
    "train_data= df.iloc[X_train_inds]\n",
    "X_train = train_data.loc[:, ~train_data.columns.isin(['srch_id','score'])]\n",
    "y_train = train_data.loc[:, train_data.columns.isin(['score'])]\n",
    "\n",
    "test_data= df.iloc[X_test_inds]\n",
    "\n",
    "#We need to keep the id for later predictions\n",
    "X_test = test_data.loc[:, ~test_data.columns.isin(['score'])]\n",
    "y_test = test_data.loc[:, test_data.columns.isin(['score'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "surprising-indonesian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         28\n",
       "1         32\n",
       "2          5\n",
       "3         21\n",
       "4         33\n",
       "          ..\n",
       "199790    32\n",
       "199791    15\n",
       "199792    24\n",
       "199793    28\n",
       "199794     6\n",
       "Name: count, Length: 199795, dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_queries[\"count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "amino-extension",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"date_time\", inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "damaged-model",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "DataFrame.dtypes for data must be int, float, bool or categorical.  When\n                categorical type is supplied, DMatrix parameter\n                `enable_categorical` must be set to `True`.date_time",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-8d353701ef36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     )\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_queries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"count\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, group, sample_weight, base_margin, eval_set, sample_weight_eval_set, eval_group, eval_metric, early_stopping_rounds, verbose, xgb_model, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1294\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m         train_dmatrix, evals = self._wrap_evaluation_matrices(\n\u001b[0m\u001b[1;32m   1297\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_margin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m             \u001b[0mfeature_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36m_wrap_evaluation_matrices\u001b[0;34m(self, X, y, group, sample_weight, base_margin, feature_weights, eval_set, sample_weight_eval_set, eval_group, label_transform)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         train_dmatrix = DMatrix(data=X, label=y, weight=sample_weight,\n\u001b[0m\u001b[1;32m    266\u001b[0m                                 \u001b[0mbase_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_margin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m                                 missing=self.missing, nthread=self.n_jobs)\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, enable_categorical)\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdispatch_data_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m         handle, feature_names, feature_types = dispatch_data_backend(\n\u001b[0m\u001b[1;32m    501\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mthreads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnthread\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py\u001b[0m in \u001b[0;36mdispatch_data_backend\u001b[0;34m(data, missing, threads, feature_names, feature_types, enable_categorical)\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_from_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_pandas_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m         return _from_pandas_df(data, enable_categorical, missing, threads,\n\u001b[0m\u001b[1;32m    540\u001b[0m                                feature_names, feature_types)\n\u001b[1;32m    541\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_pandas_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py\u001b[0m in \u001b[0;36m_from_pandas_df\u001b[0;34m(data, enable_categorical, missing, nthread, feature_names, feature_types)\u001b[0m\n\u001b[1;32m    240\u001b[0m def _from_pandas_df(data, enable_categorical, missing, nthread,\n\u001b[1;32m    241\u001b[0m                     feature_names, feature_types):\n\u001b[0;32m--> 242\u001b[0;31m     data, feature_names, feature_types = _transform_pandas_df(\n\u001b[0m\u001b[1;32m    243\u001b[0m         data, enable_categorical, feature_names, feature_types)\n\u001b[1;32m    244\u001b[0m     return _from_numpy_array(data, missing, nthread, feature_names,\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/xgboost/data.py\u001b[0m in \u001b[0;36m_transform_pandas_df\u001b[0;34m(data, enable_categorical, feature_names, feature_types, meta, meta_type)\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0mcategorical\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0msupplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDMatrix\u001b[0m \u001b[0mparameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 `enable_categorical` must be set to `True`.\"\"\"\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbad_fields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfeature_names\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmeta\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: DataFrame.dtypes for data must be int, float, bool or categorical.  When\n                categorical type is supplied, DMatrix parameter\n                `enable_categorical` must be set to `True`.date_time"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBRanker(  \n",
    "    tree_method='hist',\n",
    "    booster='gbtree',\n",
    "    objective='rank:pairwise',\n",
    "    random_state=42, \n",
    "    learning_rate=0.1,\n",
    "    colsample_bytree=0.9, \n",
    "    eta=0.05, \n",
    "    max_depth=6, \n",
    "    n_estimators=110, \n",
    "    subsample=0.75 \n",
    "    )\n",
    "\n",
    "model.fit(X_train, y_train, group=df_queries[\"count\"], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-november",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broad-voltage",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quantitative-blend",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
